AI Model Compression for Edge Deployment
========================================

This repository contains the Python scripts and supplementary materials for empirical research on compressing large AI models to enable efficient deployment on resource-constrained edge devices. The scripts implement and evaluate state-of-the-art and novel compression techniques using open-source transformer models.

Repository Contents
-------------------

To run the code in this repository, you can simply copy and paste the script into a new Google Colab notebook. Google Colab provides a free cloud-based Python environment with all required dependencies for deep learning already installed, making it easy to run experiments without a local setup.​

Instructions for Google Colab
Open Google Colab.

Create a new notebook.

Copy the relevant Python code from this repository and paste it into a cell.

Run each cell sequentially.

If the script relies on external files or models (such as those from HuggingFace), ensure to include the code for installing extra packages and downloading models within the notebook cells as well.

For best results, also upload any configuration files or small data files using Colab’s upload function, or use direct links in your code if available.​

This approach does not require any additional setup beyond what is included in the script itself and works well for most model compression workflows in academic research.
